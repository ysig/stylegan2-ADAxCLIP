# stylegan2-ADAxCLIP

A simple notebook inspired by that of https://twitter.com/advadnoun : https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR?usp=sharing
to imagine pictures from sentences based on a model (defined on the Stylegan2-ada architecture and the CLIP model)

Structuring this as a python program (cli) is on its way.


# Citations

Thanks to https://twitter.com/advadnoun for creating the original collab notebook https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR?usp=sharing !

Thanks to the creators of stylegan2-ada-pytorch!

@inproceedings{Karras2020ada,
  title     = {Training Generative Adversarial Networks with Limited Data},
  author    = {Tero Karras and Miika Aittala and Janne Hellsten and Samuli Laine and Jaakko Lehtinen and Timo Aila},
  booktitle = {Proc. NeurIPS},
  year      = {2020}
}

Stylegan2-ada-pytorch comes with a LICENSE: https://github.com/NVlabs/stylegan2-ada-pytorch/blob/main/LICENSE.txt

Thanks to the authors below & OpenAI for sharing CLIP! https://github.com/openai/CLIP

Alec Radford \* Jong Wook Kim \* Chris Hallacy Aditya Ramesh Gabriel Goh Sandhini Agarwal
Girish Sastry Amanda Askell Pamela Mishkin Jack Clark Gretchen Krueger
Ilya Sutskever
